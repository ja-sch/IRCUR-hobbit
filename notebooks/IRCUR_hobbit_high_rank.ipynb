{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44cc426f",
   "metadata": {},
   "source": [
    "# RPCA with IRCUR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e6e0f",
   "metadata": {},
   "source": [
    "We perform RPCA using IRCUR algorithm. IRCUR implementation source: https://github.com/sverdoot/robust-pca.\n",
    "\n",
    "Dataset consists of 30 video frames from 3 scenes from movie \"Hobbit\" (Sampled from: https://www.kaggle.com/datasets/akshaybapat04/frames-from-video).\n",
    "\n",
    "Frames from the same scene form low dimensional data: first frame (dim 1) + motion (dim 0-1), so data of each scene should be rank 1-2 + noise.\n",
    "We set rank upper limit to 6, our largest estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec4aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd() # should be project root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b199c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from robustpca.ircur import IRCUR # stored locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8525970",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdc2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadImageFromPath(path): #     # cv2.imread(path.as_posix())\n",
    "    return cv2.imread(path)[:,:, 0] #take just first out of three pixel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0438e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageToVector(image):\n",
    "    #image is a 3d array\n",
    "    return image.reshape((image.size,))\n",
    "\n",
    "def VectorToImage(vector, image_shape):\n",
    "    #vector is a reshaped 3d array that contained image of shape image_shape\n",
    "    return vector.reshape(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31e7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR_PATH = os.path.join(os.getcwd(), r\"data\\hobbit_dataset_selection\")\n",
    "frames_paths = [os.path.join(DATASET_DIR_PATH, filename) for filename in\n",
    "                os.listdir(DATASET_DIR_PATH)]\n",
    "#\n",
    "len(frames_paths) # number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d561ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_scenes = 3 # prior knowledge of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa070d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_frame = ReadImageFromPath(frames_paths[0])\n",
    "frame_shape = chosen_frame.shape\n",
    "frame_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32ff02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_as_arrays = np.array([ReadImageFromPath(frame_path) for frame_path in frames_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf03595",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = frames_as_arrays.shape[0]\n",
    "N # number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5e22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = no_of_scenes #number of images shown for preview\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae6767f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1) # seed chosen to be representative for scenes\n",
    "frames_to_show_ind = N//no_of_scenes * np.array(range(no_of_scenes)) + np.random.randint(low=0, high=N//no_of_scenes, size=m)\n",
    "#\n",
    "assert len(set(frames_to_show_ind)) == m\n",
    "frames_to_show_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99626c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array([ImageToVector(frame_as_array) \n",
    "                   for frame_as_array in frames_as_arrays]) # main data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d0b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pictures preview\n",
    "fig, axs = plt.subplots(1,m, figsize=(30,30))\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "for i,j in enumerate(frames_to_show_ind):\n",
    "    axs[i].imshow(VectorToImage(frames[j], image_shape=frame_shape), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a60e3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_rank = np.linalg.matrix_rank(frames)\n",
    "original_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c807b",
   "metadata": {},
   "source": [
    "## Apply IRCUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b1d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_stats(L, S, name, threshold):\n",
    "    # some stats regarding how well compressed data D is with L and S\n",
    "    # name is the name of this pair L,S (e.g. name of method that produced them, like PCP, IRCUR)\n",
    "    L_rank = np.linalg.matrix_rank(L)\n",
    "    original_nrow = S.shape[0]\n",
    "    original_ncol = S.shape[1]\n",
    "    L_relsize = L_rank * (L_rank + original_nrow + original_ncol)/(original_nrow * original_ncol)\n",
    "    S_relsize = (np.abs(S) > threshold).mean()\n",
    "    #\n",
    "    stats_dict = {'name':name, \"L_rank\":L_rank,\n",
    "                  #\"original_nrow\":original_nrow, \"original_ncol\":original_ncol,\n",
    "                  \"L_relsize\":L_relsize, \"S_relsize\":S_relsize, \"_threshold\":threshold}\n",
    "    return stats_dict\n",
    "\n",
    "def my_stats_as_df(L, S, name, threshold):\n",
    "    # returns: my_stats but as pd.DataFrame\n",
    "    \n",
    "    stats_dict = my_stats(L, S, name, threshold)\n",
    "    for key, val in [(key,val) for (key,val) in stats_dict.items() if key!=\"name\"]:\n",
    "        stats_dict[key] = [val] # make val a one-element list (except if it holds the name)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(stats_dict).set_index('name')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27f92d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_alm = IRCUR()\n",
    "rank = 6 # 6 = for each of 3 scenes: 1 \"main\" + 1 \"motion\" \n",
    "c = 4 # recommended in the paper\n",
    "nrows, ncols = int(c * rank * np.log(frame_shape[0])), int(c * rank * np.log(frame_shape[1])) # recommended in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b028bec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_ircur, S_ircur = pcp_alm.decompose(frames, rank, nrows, ncols,\n",
    "                                     thresholding_decay=0.9, initial_threshold=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5c1a8",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b40d8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stats_as_df(L_ircur, S_ircur, name=\"IRCUR\", threshold=0.05).round(2)\n",
    "# L_relsize: number of entries of an optimal CUR decomposition (computed from rank)\n",
    "# S_relsize: number of non-negligible entries of S, up to threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a329839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview: decomposition\n",
    "fig, axs = plt.subplots(2,m, figsize=(30,10))\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "for i,j in enumerate(frames_to_show_ind):\n",
    "    axs[0][i].imshow(VectorToImage(L_ircur[j], image_shape=frame_shape), cmap=\"gray\")\n",
    "    axs[0][i].set_title(\"IRCUR: L\")\n",
    "    axs[1][i].imshow(VectorToImage(S_ircur[j], image_shape=frame_shape), cmap=\"gray\")\n",
    "    axs[1][i].set_title(\"IRCUR: S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d40199",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83a95058",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d0b69c",
   "metadata": {},
   "source": [
    "We used high rank (6) (the other notebook contains low rank (3)). <br>\n",
    "Each frame was successfully decomposed into: main content of the scene + sparse noise.\n",
    "\n",
    "Sparse part has roughly 30% non-negligible entries (with threshold 0.05).\n",
    "\n",
    "High rank (6) and low rank (3) IRCUR had similar effect. Low rank ran approximately 2 times faster (... vs 378 seconds in one trial)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
